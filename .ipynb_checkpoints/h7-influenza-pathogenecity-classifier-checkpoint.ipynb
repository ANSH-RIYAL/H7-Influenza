{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBkPHmIKm8hC"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d3dcc41a7abc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPool1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Dense, Input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential, utils\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "-Qo-j2wsm8hS",
    "outputId": "f4d9f921-cd46-4021-aa58-0c5a2ab87962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Pathogenic cases: 938\n",
      "Low Pathogenic cases: 862\n",
      "(1800,)\n"
     ]
    }
   ],
   "source": [
    "# Load data in records, and outputs in y\n",
    "data = pd.read_csv(\"./H7.csv\")\n",
    "data = data.iloc[:]\n",
    "records = data[\"HA\"].apply(lambda x: np.array(list(x))).values\n",
    "y = data[\"Pathogenicity\"].values\n",
    "\n",
    "print('Highly Pathogenic cases:', np.count_nonzero(y==\"HP\"))\n",
    "print('Low Pathogenic cases:', np.count_nonzero(y==\"LP\"))\n",
    "print(records.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jb2vOmCAm8hh"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'records' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-21daeb3f9f55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# preprocess input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mle_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'records' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocess input data\n",
    "sequence = records\n",
    "le_1 = LabelEncoder()\n",
    "y = le_1.fit_transform(y) \n",
    "y = tf.one_hot(y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZDhr84FNw0bL",
    "outputId": "b40d5d4a-55c5-4379-aaf9-a4fc98eda899"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b4851f32e920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mseqEncoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mseqEncoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "seqEncoded = np.zeros((len(records),len(records[0])), dtype=int)\n",
    "for i, seq in enumerate(sequence):\n",
    "    seqEncoded[i] = le.fit_transform(seq)\n",
    "\n",
    "oneHotSeq = tf.one_hot(seqEncoded, depth=21).numpy()\n",
    "\n",
    "# remove alignment character's one hot\n",
    "for seq in oneHotSeq:\n",
    "    for protein in seq:\n",
    "        if protein[0] == 1:\n",
    "            protein[0] = 0\n",
    "print('(samples, proteins, one-hot-encoding) ::',oneHotSeq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "VUwmufveAWXO",
    "outputId": "de2c9dbf-80b9-4322-f49d-c2a68682013e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(oneHotSeq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "s = {}\n",
    "for i in range(oneHotSeq.shape[0]):\n",
    "    s[str(oneHotSeq[i])] = 1\n",
    "print(str(oneHotSeq[0]))\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "se8Kcw7S3hf5",
    "outputId": "ce870628-728e-4e36-e3be-d945a2f4ac1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "1350\n",
      "1350\n",
      "450\n",
      "450\n",
      "1800 1800\n"
     ]
    }
   ],
   "source": [
    "trainTestValues=[]\n",
    "noOfEntries=oneHotSeq.shape[0]\n",
    "for i in range(noOfEntries):\n",
    "  itemArray=[oneHotSeq[i],y[i]]\n",
    "  trainTestValues.append(itemArray)\n",
    "shuffle(trainTestValues)\n",
    "testSplitIndex=int(noOfEntries*0.75)\n",
    "train=trainTestValues[:testSplitIndex]\n",
    "test=trainTestValues[testSplitIndex:]\n",
    "X_train=[i[0] for i in train]\n",
    "X_train=np.array(X_train)\n",
    "print(X_train[0])\n",
    "y_train=[i[1] for i in train]\n",
    "X_test=[i[0] for i in test]\n",
    "y_test=[i[1] for i in test]\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))\n",
    "print(len(X_train)+len(X_test),noOfEntries)\n",
    "#X_train,y_train,X_test,y_test = train_test_split(oneHotSeq,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-8a0e7ec8f40f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please select a network so that I can alter the finer details in the model / training process as needed\n",
    "# I'm using cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input is in the shape of [number of samples, length of 1 sample/ number of proteins in the sequence, length of OHE]\n",
    "'''\n",
    "class h5CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(h5CNN, self).__init__()\n",
    "        self.conv  = nn.Conv1d(in_channels = 1, out_channels = 20, kernel_size = (2,length of OHE))\n",
    "        self.dense = nn.Linear(in_features = number, out_features = 120) #number to be derived by the formula after knowing the number of samples\n",
    "        self.out = nn.Linear(in_features = 120, out_features = 2)\n",
    "    def forward(self,t):\n",
    "        \n",
    "        # Conv1d\n",
    "        t = self.conv(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # Flatten then Dense\n",
    "        t = t.reshape(-1,number) # Flatten\n",
    "        t = self.dense(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # Out\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "sBrG8nGpm8hs",
    "outputId": "d66bc888-7613-40b7-9ca6-c3c4b75271c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 294, 20)           860       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 147, 20)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2940)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 5882      \n",
      "=================================================================\n",
      "Total params: 6,742\n",
      "Trainable params: 6,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 589, 21)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 294, 20)           860       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 147, 20)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2940)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 5882      \n",
      "=================================================================\n",
      "Total params: 6,742\n",
      "Trainable params: 6,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "the shape of the input is supposed to be in the form of :\n",
    "[no. of training values, length of OHE, number of proteins]\n",
    "as conv1d kernel slides over the last dimension.\n",
    "'''\n",
    "\n",
    "class h5CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(h5CNN, self).__init__()\n",
    "        self.conv  = nn.Conv1d(in_channels = len(OHE), out_channels = 20, kernel_size = 2, padding = 0) # padding according to maxpool values\n",
    "        self.dense = nn.Linear(in_features = 2940, out_features = 120) # in shape has to be changed, I copied the one used in the last one\n",
    "        self.out = nn.Linear(in_features = 120, out_features = 2)\n",
    "    \n",
    "    def forward(self,t):\n",
    "        \n",
    "        # Conv1d\n",
    "        t = self.conv(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "                \n",
    "        # Flattening and then Dense\n",
    "        t = t.reshape(-1,t.shape[0]*t.shape[1]) # pls change according to whatever the shape is\n",
    "        t = self.dense(t)\n",
    "        t = F.relu(t)\n",
    "                \n",
    "        # Out\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = h5CNN()\n",
    "network.cuda()\n",
    "print(next(network.parameters()).is_cuda)\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function has to be custom defined cuz there will be a lot of confusion with OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    X_train, batch_size = 100)\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        labels= batch[:,3]\n",
    "        seq= batch[:,:2].reshape(-1,1,28,28)\n",
    "        preds = network(seq)\n",
    "        #loss = F.cross_entropy(preds,labels)\n",
    "        loss = F.OHE_cross_entropy(preds,labels)\n",
    "        # For using cross-entropy loss in oneHotEncoded tensor target, either unsqueeze OHE to 1 less dimensional tensor\n",
    "        # or define a custom loss function. Pytorch calculates loss between an N x (categories) tensor and an 1 x N tensor\n",
    "        # ie. between shapes [batch_size,categories] and [categories] by using categories as index of batch_size 1D tensor.\n",
    "        # It's not advisable to override the cross_entropy predefined functions of Pytorch.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_correct += preds.argmax(dim = 1).eq(labels).sum()\n",
    "\n",
    "    print(\"epoch\", epoch, \"total correct = \", int(total_correct), \"total loss = \", total_loss)\n",
    "    print(int(total_correct)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the things below are kept for reference ie. for values to be replicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXkXmkgWm8h2"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# compiling model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIyzYbg8m8h_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1080 samples, validate on 270 samples\n",
      "Epoch 1/25\n",
      "1080/1080 [==============================] - 1s 602us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2/25\n",
      "1080/1080 [==============================] - 0s 307us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9852\n",
      "Epoch 3/25\n",
      "1080/1080 [==============================] - 0s 302us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 4/25\n",
      "1080/1080 [==============================] - 0s 299us/sample - loss: 6.4443e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 5/25\n",
      "1080/1080 [==============================] - 0s 304us/sample - loss: 5.2759e-04 - accuracy: 1.0000 - val_loss: 8.8531e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/25\n",
      "1080/1080 [==============================] - 0s 304us/sample - loss: 4.7615e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 7/25\n",
      "1080/1080 [==============================] - 0s 304us/sample - loss: 4.1472e-04 - accuracy: 1.0000 - val_loss: 7.4112e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/25\n",
      "1080/1080 [==============================] - 0s 312us/sample - loss: 3.5863e-04 - accuracy: 1.0000 - val_loss: 8.3825e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/25\n",
      "1080/1080 [==============================] - 0s 350us/sample - loss: 3.1469e-04 - accuracy: 1.0000 - val_loss: 8.9759e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/25\n",
      "1080/1080 [==============================] - 0s 295us/sample - loss: 2.7510e-04 - accuracy: 1.0000 - val_loss: 5.3920e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "1080/1080 [==============================] - 0s 305us/sample - loss: 2.6764e-04 - accuracy: 1.0000 - val_loss: 6.1673e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "1080/1080 [==============================] - 0s 306us/sample - loss: 2.4096e-04 - accuracy: 1.0000 - val_loss: 5.2723e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "1080/1080 [==============================] - 0s 298us/sample - loss: 2.1666e-04 - accuracy: 1.0000 - val_loss: 4.9335e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "1080/1080 [==============================] - 0s 364us/sample - loss: 1.7776e-04 - accuracy: 1.0000 - val_loss: 5.6262e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "1080/1080 [==============================] - 0s 375us/sample - loss: 1.8032e-04 - accuracy: 1.0000 - val_loss: 4.1951e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "1080/1080 [==============================] - 0s 322us/sample - loss: 1.5119e-04 - accuracy: 1.0000 - val_loss: 3.3562e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "1080/1080 [==============================] - 0s 366us/sample - loss: 1.4476e-04 - accuracy: 1.0000 - val_loss: 3.8627e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "1080/1080 [==============================] - 0s 345us/sample - loss: 1.3375e-04 - accuracy: 1.0000 - val_loss: 3.6115e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "1080/1080 [==============================] - 0s 320us/sample - loss: 1.2242e-04 - accuracy: 1.0000 - val_loss: 3.0871e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "1080/1080 [==============================] - 0s 303us/sample - loss: 1.0492e-04 - accuracy: 1.0000 - val_loss: 4.1454e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "1080/1080 [==============================] - 0s 308us/sample - loss: 9.9029e-05 - accuracy: 1.0000 - val_loss: 3.1219e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "1080/1080 [==============================] - 0s 357us/sample - loss: 8.8471e-05 - accuracy: 1.0000 - val_loss: 3.5276e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "1080/1080 [==============================] - 0s 328us/sample - loss: 8.3451e-05 - accuracy: 1.0000 - val_loss: 3.8728e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "1080/1080 [==============================] - 0s 318us/sample - loss: 8.1051e-05 - accuracy: 1.0000 - val_loss: 3.7577e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "1080/1080 [==============================] - 0s 327us/sample - loss: 7.2311e-05 - accuracy: 1.0000 - val_loss: 2.5711e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# training model\n",
    "# Due to lack of data model is underfitting (training loss >> validation loss)\n",
    "#class_weights = {0: 1.,\n",
    "                 #1: 5}\n",
    "\n",
    "history = model.fit(\n",
    "  np.array(X_train), np.array(y_train),\n",
    "  batch_size=16,\n",
    "  epochs=25,\n",
    "  validation_split=0.2,\n",
    "  shuffle=True\n",
    "  #class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqrhDlrh3vTj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       248\n",
      "           1       1.00      1.00      1.00       202\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       450\n",
      "   macro avg       1.00      1.00      1.00       450\n",
      "weighted avg       1.00      1.00      1.00       450\n",
      " samples avg       1.00      1.00      1.00       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(np.array(X_test))\n",
    "y_pred=y_pred>0.5\n",
    "print(classification_report(np.array(y_test),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d30053bf3eb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dark_background'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,101)\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(epochs, loss_train, 'r', label='Training Loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_train = history.history['accuracy']\n",
    "acc_val = history.history['val_accuracy']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs, acc_train, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, acc_val, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1800 into shape (1800,589)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-1608fc5d8ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m589\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1800 into shape (1800,589)"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "H5 Avian Influenza Pathogenicity Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
